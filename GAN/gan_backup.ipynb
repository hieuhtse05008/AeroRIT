{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of hyperspectral samples using Wasserstein-GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wasserstein-GANs are Generative Adversarial Models that can be used to generate synthetic data that approximates a specific input distribution of real data.\n",
    "\n",
    "In this notebook, we show how to use such a tool to generate *ex nihilo* synthetic hyperspectral samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T13:11:31.289167Z",
     "start_time": "2018-07-11T13:11:26.197215Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from scipy.io import loadmat\n",
    "from skimage import io\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the Pavia University dataset. The `.mat` files are available on [this website](http://www.ehu.eus/ccwintco/index.php?title=Hyperspectral_Remote_Sensing_Scenes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T13:11:31.925019Z",
     "start_time": "2018-07-11T13:11:31.293152Z"
    }
   },
   "outputs": [],
   "source": [
    "# img = loadmat('./PaviaU.mat')['paviaU']\n",
    "# gt = loadmat('./PaviaU_gt.mat')['paviaU_gt']\n",
    "# mask = np.random.randint(0, 100, gt.shape) < 5\n",
    "# train_gt = np.copy(gt)\n",
    "# train_gt[np.nonzero(~mask)] = 0\n",
    "# test_gt = np.copy(gt)\n",
    "# test_gt[train_gt > 0] = 0\n",
    "# rgb = img[:,:,(55,41,12)]\n",
    "# rgb = (255 * (rgb.astype(np.float32) - rgb.min())/(rgb.max() - rgb.min())).astype(np.uint8)\n",
    "# print(np.shape(img))\n",
    "# print(np.shape(gt))\n",
    "# print(np.shape(train_gt))\n",
    "# print(np.shape(rgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(img[0][0])\n",
    "# print(img[img > 1])\n",
    "counts = np.asarray(np.unique(gt,return_counts=True))\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gt =  np.rot90(gt,1,(0,1))\n",
    "\n",
    "# classes = np.array([\n",
    "#     [153 ,  0 ,  0], #unspecified\n",
    "#     [  0 ,  0 ,255], #roads\n",
    "#     [  0, 255 ,  0], #vegetation\n",
    "#     [  0 ,255 ,255], #water\n",
    "#     [255 ,  0 ,0],#buidings \n",
    "#     [255 ,127 , 80]#cars\n",
    "# ])\n",
    "# # d = {\n",
    "# #     repr([153 ,  0 ,  0]): 0,\n",
    "# #     repr([0 ,  0 ,255]): 1,\n",
    "# #     repr([ 0, 255 ,  0]): 2,\n",
    "# #     repr([ 0 ,255 ,255]): 3,\n",
    "# #     repr([255 ,  0 ,0]): 4,\n",
    "# #     repr([255 ,127 , 80]): 5,\n",
    "# # }\n",
    "# gt_temp = np.zeros((gt.shape[0],gt.shape[1]))\n",
    "\n",
    "# for i in range(gt.shape[0]):\n",
    "#     for j in range(gt.shape[1]):\n",
    "#         val = gt[i][j]\n",
    "#         for id in range(len(classes)):\n",
    "#             if np.array_equal(val, classes[id]):\n",
    "#                 gt_temp[i][j] = id\n",
    "        \n",
    "        \n",
    "# gt = gt_temp        \n",
    "# gt_new = Image.fromarray(gt)\n",
    "# gt_new.save('gt_new.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = io.imread('C:\\\\Users\\\\golde\\\\Documents\\\\GitHub\\\\AeroRIT\\\\Aerial Data\\\\Collection\\\\image_hsi_radiance.tif')\n",
    "# img_rgb = io.imread('C:\\\\Users\\\\golde\\\\Documents\\\\GitHub\\\\AeroRIT\\\\Aerial Data\\\\Collection\\\\image_rgb.tif')\n",
    "img = io.imread('E:\\\\Accessories\\\\Documents\\\\Python Scripts\\\\AeroRIT\\\\Aerial Data\\\\Collection\\\\image_hsi_radiance.tif')\n",
    "img_rgb = io.imread('E:\\\\Accessories\\\\Documents\\\\Python Scripts\\\\AeroRIT\\\\Aerial Data\\\\Collection\\\\image_rgb.tif')\n",
    "# E:\\Accessories\\Documents\\Python Scripts\\AeroRIT\\Aerial Data\n",
    "# gt = io.imread('C:\\\\Users\\\\golde\\\\Documents\\\\GitHub\\\\AeroRIT\\\\Aerial Data\\\\Collection\\\\image_labels.tif')\n",
    "gt = io.imread('./gt_new.tif')\n",
    "gt = gt.astype(int)\n",
    "\n",
    "img = np.rot90(img,1,(0,2))\n",
    "img_rgb =  np.rot90(img_rgb,1,(0,1))\n",
    "\n",
    "# crop images\n",
    "crop_offset = 348\n",
    "crop_w = 610*2 + crop_offset\n",
    "crop_h = 340*2 + crop_offset\n",
    "\n",
    "img = img[crop_offset:crop_w,crop_offset:crop_h,:]\n",
    "img_rgb = img_rgb[crop_offset:crop_w,crop_offset:crop_h,:]\n",
    "gt = gt[crop_offset:crop_w,crop_offset:crop_h]\n",
    "# img = img[:3974,:1972,:]\n",
    "# img_rgb = img_rgb[:3974,:1972,:]\n",
    "# gt = gt[:3974,:1972]\n",
    "counts = np.asarray(np.unique(gt,return_counts=True))\n",
    "print(counts)\n",
    "print(np.shape(img))\n",
    "print(np.shape(img_rgb))\n",
    "print(gt.shape)\n",
    "\n",
    "mask = np.random.randint(0, 100, gt.shape) < 5\n",
    "train_gt = np.copy(gt)\n",
    "train_gt[np.nonzero(~mask)] = 0\n",
    "test_gt = np.copy(gt)\n",
    "test_gt[train_gt > 0] = 0\n",
    "rgb = img_rgb\n",
    "rgb = (255 * (rgb.astype(np.float32) - rgb.min())/(rgb.max() - rgb.min())).astype(np.uint8)\n",
    "print(np.shape(img))\n",
    "print(np.shape(gt))\n",
    "print(np.shape(train_gt))\n",
    "print(np.shape(rgb))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ground truth is shown below. We sample 10% from the pixels as training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T13:11:32.419765Z",
     "start_time": "2018-07-11T13:11:31.928291Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.add_subplot(141)\n",
    "plt.imshow(rgb)\n",
    "plt.title(\"Composite\")\n",
    "fig.add_subplot(142)\n",
    "plt.imshow(gt)\n",
    "plt.title(\"Full ground truth\")\n",
    "fig.add_subplot(143)\n",
    "plt.imshow(mask)\n",
    "\n",
    "plt.title(\"Mask\")\n",
    "fig.add_subplot(144)\n",
    "plt.imshow(train_gt)\n",
    "plt.title(\"Train ground truth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a `HyperX` class to hold the dataset. Note that the label is encoded as a one-hot vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T13:11:33.849757Z",
     "start_time": "2018-07-11T13:11:32.421269Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "\n",
    "class HyperX(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, data, ground_truth, semi=False):\n",
    "        super(HyperX, self).__init__()\n",
    "        # print('init dataloader')\n",
    "        # Normalize the data in [0,1]\n",
    "        data = (data - data.min()) / (data.max() - data.min())\n",
    "        self.data = data\n",
    "        self.gt = ground_truth\n",
    "        self.n_classes = len(np.unique(ground_truth))\n",
    "        if semi:\n",
    "            # Semi-supervision, include neighbours at 50px\n",
    "            x_pos, y_pos = np.nonzero(morphology.dilation(ground_truth > 0, morphology.disk(50)))\n",
    "        else:\n",
    "            x_pos, y_pos = np.nonzero(ground_truth)\n",
    "        self.indices = [idx for idx in zip(x_pos, y_pos)]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        x, y = self.indices[i]\n",
    "        data = self.data[x,y]\n",
    "        # Get the label in one-hot encoded style\n",
    "        # print(self.n_classes,x, y,np.eye(self.n_classes),self.gt[x, y])\n",
    "        label = np.asarray(np.eye(self.n_classes)[self.gt[x, y]], dtype='int64')\n",
    "        return torch.from_numpy(data), torch.from_numpy(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T13:11:34.137905Z",
     "start_time": "2018-07-11T13:11:33.852165Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Basic generator that maps: noise + condition -> fake samples\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        # LeakyReLU is preferred to keep gradients flowing even for negative activations\n",
    "        self.generator = torch.nn.Sequential(\n",
    "            torch.nn.Linear(z_dim + c_dim, h_dim),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(h_dim, h_dim),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(h_dim, h_dim),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(h_dim, X_dim),\n",
    "            torch.nn.Sigmoid() # smooth [0,1] outputs\n",
    "        )\n",
    "        self.apply(weight_init)\n",
    "\n",
    "    def forward(self, z, c):\n",
    "        # Concatenate the noise and condition\n",
    "        inputs = torch.cat([z, c], 1)\n",
    "        return self.generator(inputs)\n",
    "\n",
    "# Basic fully connected discriminator: sample -> -infty -- fake - 0 - real -- +infty\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.discriminator = torch.nn.Sequential(\n",
    "            torch.nn.Linear(X_dim, h_dim),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(h_dim, h_dim),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(h_dim, h_dim),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(h_dim, 1)\n",
    "        )\n",
    "        \n",
    "        self.apply(weight_init)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.discriminator(X)\n",
    "\n",
    "# Basic fully connected classifier: sample -> class\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.discriminator = torch.nn.Sequential(\n",
    "            torch.nn.Linear(X_dim, h_dim),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(h_dim, h_dim),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(h_dim, h_dim),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(h_dim, c_dim)\n",
    "        )\n",
    "        \n",
    "        self.apply(weight_init)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.discriminator(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T13:11:42.366462Z",
     "start_time": "2018-07-11T13:11:34.141187Z"
    }
   },
   "outputs": [],
   "source": [
    "mb_size = 256 # Batch size\n",
    "z_dim = 30   # Noise dimension\n",
    "X_dim = img.shape[-1] # Number of bands\n",
    "print(X_dim)\n",
    "h_dim = 512  # Hidden layer size\n",
    "d_step = 5   # Number of discriminator training steps for ea ch generator training step\n",
    "lr = 5e-5    # Learning rate\n",
    "c_weight = 0.2 # Auxiliary classifier weight\n",
    "flip_percentage = 0.0 # Proportion of label flipping\n",
    "mixup_alpha = 0.1 # Mixup\n",
    "semi_supervised = True # semi-supervision (set to True to include unlabeled samples)\n",
    "\n",
    "# Build the dataset and data loader\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    HyperX(img, train_gt if semi_supervised else gt), batch_size=mb_size, shuffle=True)\n",
    "# c_dim = condition vector size\n",
    "c_dim = data_loader.dataset.n_classes\n",
    "print(c_dim)\n",
    "# Ignore the class 0\n",
    "class_weights = torch.ones((c_dim))\n",
    "class_weights[0] = 0.\n",
    "class_weights = class_weights.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T13:11:42.381045Z",
     "start_time": "2018-07-11T13:11:42.368312Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize weights using the He et al. (2015) policy.\n",
    "def weight_init(m):\n",
    "    if isinstance(m, (nn.Linear, nn.Conv2d, nn.Conv3d, nn.ConvTranspose3d)):\n",
    "        torch.nn.init.kaiming_normal_(m.weight.data)\n",
    "\n",
    "# Spherical interpolation between two vectors on the unit hypersphere\n",
    "# See : https://github.com/soumith/dcgan.torch/issues/14\n",
    "def slerp(val, low, high):\n",
    "    omega = np.arccos(np.clip(np.dot(low/np.linalg.norm(low), high/np.linalg.norm(high)), -1, 1))\n",
    "    so = np.sin(omega)\n",
    "    if so == 0:\n",
    "        return (1.0-val) * low + val * high # L'Hopital's rule/LERP\n",
    "    return np.sin((1.0-val)*omega) / so * low + np.sin(val*omega) / so * high\n",
    "\n",
    "def lerp(val, low, high):\n",
    "    return (1.0-val) * low + val * high # L'Hopital's rule/LERP\n",
    "\n",
    "# Gradient penalty from the Improved WGAN training\n",
    "# From : https://github.com/EmilienDupont/wgan-gp\n",
    "# Use penalty_weight set at 10, as suggested in the paper\n",
    "def calc_gradient_penalty(netD, real_data, generated_data, penalty_weight=10):\n",
    "        batch_size = real_data.size()[0]\n",
    "\n",
    "        alpha = torch.rand(batch_size, 1) if real_data.dim() == 2 else torch.rand(batch_size, 1, 1, 1)\n",
    "        alpha = alpha.expand_as(real_data)\n",
    "        alpha = alpha.cuda()\n",
    "        \n",
    "        interpolated = alpha * real_data + (1 - alpha) * generated_data\n",
    "        #interpolated = Variable(interpolated, requires_grad=True)\n",
    "        interpolated.requires_grad_()\n",
    "        interpolated = interpolated.cuda()\n",
    "\n",
    "        # Calculate probability of interpolated examples\n",
    "        prob_interpolated = netD(interpolated)\n",
    "\n",
    "        # Calculate gradients of probabilities with respect to examples\n",
    "        gradients = torch.autograd.grad(outputs=prob_interpolated, inputs=interpolated,\n",
    "                               grad_outputs=torch.ones(prob_interpolated.size()).cuda(),\n",
    "                               create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        # Gradients have shape (batch_size, num_channels, img_width, img_height),\n",
    "        # so flatten to easily take norm per example in batch\n",
    "        gradients = gradients.view(batch_size, -1)\n",
    "\n",
    "        # Derivatives of the gradient close to 0 can cause problems because of\n",
    "        # the square root, so manually calculate norm and add epsilon\n",
    "        gradients_norm = torch.sqrt(torch.sum(gradients ** 2, dim=1) + 1e-12)\n",
    "\n",
    "        # Return gradient penalty\n",
    "        return penalty_weight * ((gradients_norm - 1) ** 2).mean()\n",
    "    \n",
    "def reset_grad(*nets):\n",
    "    for net in nets:\n",
    "        net.zero_grad()\n",
    "        \n",
    "def plot_mean_std(samples):\n",
    "    mean_spectrum = np.mean(samples, axis=0)\n",
    "    std_spectrum = np.std(samples, axis=0)\n",
    "    plt.plot(mean_spectrum - std_spectrum, linestyle='dotted', label='-std')\n",
    "    plt.plot(mean_spectrum, label='mean')\n",
    "    plt.plot(mean_spectrum + std_spectrum, linestyle='dotted', label='+std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T15:47:02.091974Z",
     "start_time": "2018-07-11T13:11:42.382983Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get networks\n",
    "G = Generator().cuda()\n",
    "D = Discriminator().cuda()\n",
    "C = Classifier().cuda()\n",
    "\n",
    "# Use RMSProp optimizer\n",
    "G_solver = optim.RMSprop(G.parameters(), lr=lr)\n",
    "D_solver = optim.RMSprop(D.parameters(), lr=lr)\n",
    "C_solver = optim.RMSprop(C.parameters(), lr=lr)\n",
    "\n",
    "for it in tqdm(range(100000)):\n",
    "    ###########################\n",
    "    # (1) Update C and D      #\n",
    "    ###########################\n",
    "    for p in D.parameters():  # reset requires_grad\n",
    "        p.requires_grad = True  # they are set to False below in netG update\n",
    "    for p in C.parameters():\n",
    "        p.requires_grad = True\n",
    "    \n",
    "    # D is trained d_step times for each iteration\n",
    "    \n",
    "    for _, (X, y), (X_, y_) in zip(range(d_step), data_loader, data_loader):\n",
    "        D.zero_grad()\n",
    "\n",
    "        # Sample random noise\n",
    "        z = torch.randn(y.size(0), z_dim).squeeze()\n",
    "        X, y = X.float(), y.float()\n",
    "        X_, y_ = X_.float(), y_.float()\n",
    "        # Mixup\n",
    "        lam = np.random.beta(mixup_alpha, mixup_alpha)\n",
    "        X = lam*X + (1. - lam)*X_\n",
    "        X, y, z = X.cuda(), y.cuda(), z.cuda()\n",
    "        y_ = y_.cuda()\n",
    "        \n",
    "        # Get discriminator prediction on real samples\n",
    "        D_real = D(X).mean()\n",
    "        # Get discriminator prediction on fake samples\n",
    "        fake_samples = G(z, y)\n",
    "        D_fake = D(fake_samples).mean()\n",
    "        # Compute gradient penalty\n",
    "        gradient_penalty = calc_gradient_penalty(D, X.data, fake_samples.data)\n",
    "        # Compute loss and backpropagate\n",
    "        D_loss = D_fake - D_real + gradient_penalty\n",
    "        flip = np.random.random() < flip_percentage\n",
    "        if flip: \n",
    "            # Flip real and fake\n",
    "            gradient_penalty = calc_gradient_penalty(D, fake_samples.data, X.data)\n",
    "            D_loss = D_real - D_fake + gradient_penalty\n",
    "        D_loss.backward()\n",
    "        D_solver.step()\n",
    "    \n",
    "        ######################\n",
    "        #  Update C network  #\n",
    "        ######################\n",
    "        C.zero_grad()\n",
    "        # Get class values\n",
    "        _, classes = torch.max(y, dim=1)\n",
    "        _, classes_ = torch.max(y_, dim=1)\n",
    "        # Get predictions from C\n",
    "        if flip:\n",
    "            fake_samples = G(z, y)\n",
    "            pred = C(fake_samples)\n",
    "            # Compute loss and backpropagate\n",
    "            C_loss = F.cross_entropy(pred, classes, weight=class_weights)\n",
    "        else:\n",
    "            pred = F.log_softmax(C(X))\n",
    "            C_loss = lam * F.nll_loss(pred, classes) + (1. - lam) * F.nll_loss(pred, classes_)\n",
    "        C_loss.backward()\n",
    "        C_solver.step()\n",
    "\n",
    "\n",
    "    ############################\n",
    "    # (2) Update G network\n",
    "    ###########################\n",
    "    for p in D.parameters():\n",
    "        p.requires_grad = False  # to avoid computation\n",
    "    for p in C.parameters():\n",
    "        p.requires_grad = False\n",
    "    reset_grad(C, G, D)\n",
    "\n",
    "    # Sample random noise\n",
    "    z = torch.randn(y.size(0), z_dim).squeeze()\n",
    "    z = z.cuda()\n",
    "    # Generate fake samples\n",
    "    G_sample = G(z, y)\n",
    "    D_fake = D(G_sample)\n",
    "    pred = C(G_sample)\n",
    "    C_loss = F.cross_entropy(pred, classes, weight=class_weights)\n",
    "    # Fool the discriminator (WGAN)\n",
    "    G_loss = -torch.mean(D_fake)\n",
    "    # Include the auxialiary classifier loss (AC-GAN)\n",
    "    loss = G_loss + c_weight * C_loss\n",
    "    # Backpropagate\n",
    "    loss.backward()\n",
    "    G_solver.step()\n",
    "\n",
    "    # Print and plot every now and then\n",
    "    if it % 1000 == 0:\n",
    "        with torch.no_grad():\n",
    "            print('Iter-{}; D_loss: {}; G_loss: {}; C_loss: {}'.format(it,\n",
    "                                                           D_loss.data.cpu().numpy(), G_loss.data.cpu().numpy(),\n",
    "                                                           C_loss.data.cpu().numpy()))\n",
    "            z = torch.randn(mb_size, z_dim).squeeze().cuda()\n",
    "            c = np.zeros(shape=[mb_size, c_dim], dtype='float32')\n",
    "            idx = np.random.randint(1, data_loader.dataset.n_classes)\n",
    "            c[:, idx] = 1.\n",
    "            c = torch.from_numpy(c).squeeze().cuda()\n",
    "            samples = G(z, c).data.cpu().numpy()[:16]\n",
    "            pred = G(z, c)\n",
    "            plot_mean_std(samples)\n",
    "            plt.title(\"Samples for class {}\".format(idx))\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T12:44:20.311836Z",
     "start_time": "2018-05-30T12:44:20.306598Z"
    }
   },
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the generator has been trained, we can generate some fake spectra and see how they fare visually against the real ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T15:47:04.680072Z",
     "start_time": "2018-07-11T15:47:02.093967Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for c in np.unique(gt):\n",
    "    # 0 is the \"undefined\" class\n",
    "    if c == 0:\n",
    "        continue\n",
    "    \n",
    "    # Get the mean spectrum +- std for this class\n",
    "    spectras = img[gt == c, :]\n",
    "    plot_mean_std(spectras)\n",
    "    plt.title(\"Real {}\".format(c))\n",
    "    plt.show()\n",
    "    \n",
    "    # Get as many fake spectras as real ones\n",
    "    synthetic_spectras = []\n",
    "    with torch.no_grad():\n",
    "        while len(synthetic_spectras) < len(spectras):\n",
    "            z = torch.randn(mb_size, z_dim).cuda()\n",
    "            y = torch.from_numpy(np.eye(data_loader.dataset.n_classes)[c]).float()\n",
    "            y = y.unsqueeze(0).repeat(mb_size, 1).cuda()\n",
    "            G_sample = G(z, y)\n",
    "            _, classes = torch.max(y, 1)\n",
    "            _, pred = torch.max(C(G_sample), 1)\n",
    "            synthetic_spectras += list(G_sample.cpu().data.numpy())\n",
    "    plt.show()\n",
    "    plot_mean_std(synthetic_spectras)\n",
    "    plt.title(\"Synthetic {}\".format(c))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_img = np.array(img.shape)\n",
    "channels    =  np.array([])\n",
    "counts = np.asarray(np.unique(gt,return_counts=True))[1]\n",
    "\n",
    "for channel_label in np.unique(gt):\n",
    "    \n",
    "    generate_size = counts[channel_label]\n",
    "    z = torch.randn(generate_size, z_dim).cuda()\n",
    "    y = torch.from_numpy(np.eye(data_loader.dataset.n_classes)[channel_label]).float()\n",
    "    y = y.unsqueeze(0).repeat(generate_size, 1).cuda()\n",
    "    G_sample = G(z, y)\n",
    "    # print(channel_label, generate_size, G_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_loader.dataset.n_classes)\n",
    "\n",
    "for channel_label in np.unique(gt):\n",
    "    z = torch.randn(mb_size, z_dim).cuda()\n",
    "    y = torch.from_numpy(np.eye(data_loader.dataset.n_classes)[channel_label]).float()\n",
    "    y = y.unsqueeze(0).repeat(mb_size, 1).cuda()\n",
    "    G_sample = G(z, y)\n",
    "    # print(G_sample)\n",
    "    # print(np.shape(z),np.shape(y))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM on fake data\n",
    "\n",
    "We now generate some fake data (in the same quantities as the real data) and apply the trained SVM on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T15:47:15.606669Z",
     "start_time": "2018-07-11T15:47:15.597884Z"
    }
   },
   "outputs": [],
   "source": [
    "def gan_create_fake_dataset(labels):\n",
    "    with torch.no_grad():\n",
    "        spectras = []\n",
    "        for l in np.array_split(labels, len(labels) // mb_size):\n",
    "            \n",
    "            z = torch.randn(len(l), z_dim).cuda()\n",
    "            y = np.zeros((len(l), data_loader.dataset.n_classes))\n",
    "            for i, label in enumerate(l):\n",
    "                y[i] = np.eye(data_loader.dataset.n_classes)[label]\n",
    "            y = torch.from_numpy(y).float()\n",
    "            eps = torch.randn(y.size())/10\n",
    "            #y += eps\n",
    "            y = y.cuda()\n",
    "            G_sample = G(z, y)\n",
    "            spectras += list(G_sample.cpu().data.numpy())\n",
    "        return np.array(spectras), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (unique, counts) = np.unique(gt, return_counts=True)\n",
    "# frequencies = np.asarray((unique, counts)).T\n",
    "# print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "_gt = np.array([gt[x,y] for x,y in zip(*np.nonzero(gt))])\n",
    "_axis_x = np.array([x for x,y in zip(*np.nonzero(gt))])\n",
    "_axis_y = np.array([y for x,y in zip(*np.nonzero(gt))])\n",
    "out_pixels, out_gt_img = gan_create_fake_dataset(_gt)\n",
    "input_width = np.shape(img)[0]\n",
    "input_height = np.shape(img)[1]\n",
    "\n",
    "# test_img = np.reshape(out_img,(input_width,-1,X_dim) )\n",
    "# print(np.shape(test_img))\n",
    "\n",
    "out_img = np.copy(img)\n",
    "for i in range(len(_gt)):\n",
    "    x = _axis_x[i]\n",
    "    y = _axis_y[i]\n",
    "    if gt[x][y] > 0:\n",
    "        out_img[x][y] = out_pixels[i]\n",
    "print(np.shape(_gt))\n",
    "print(np.shape(img))\n",
    "print(np.shape(out_img))\n",
    "print(np.shape(out_gt_img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(out_pixels[out_pixels > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import matplotlib\n",
    "\n",
    "# matplotlib.image.imsave(\"./output_images/out_img.tif\", out_img)\n",
    "# im = Image.new('L', (input_width, input_height))\n",
    "# im.putdata(out_img.flatten().tolist())\n",
    "# im.save(\"filename.tiff\", format=\"TIFF\", save_all=True)\n",
    "out_rgb = out_img[:,:,(55,41,12)]\n",
    "\n",
    "matplotlib.image.imsave(\"./output_images/out_rgb.png\", out_rgb)\n",
    "\n",
    "\n",
    "savedict = {\n",
    "    'paviaU_out' : out_img,\n",
    "}\n",
    "sio.savemat('./output_images/out_img.mat', savedict)\n",
    "\n",
    "#out_gt_img = Image.fromarray(out_gt_img)\n",
    "#out_img.save(\"./output_images/out_img.tif\")\n",
    "#out_gt_img.save(\"./output_images/out_gt_img.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('aerorit')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "89abf092b880c9f44ce1e686c97db8e09d679c366f99038f07a98950d2bc11a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
